{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "# print(openai_key)\n",
    "\n",
    "gemeni_key = os.getenv(\"GEMENI_API_KEY\")\n",
    "# print(gemeni_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking!  How are you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-002\", google_api_key=gemeni_key)\n",
    "\n",
    "response = model.invoke(\"Hello, how are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# prompt_template_name = PromptTemplate( input_variables=['book'],\n",
    "#                template=\"i want review of this book in one line , the book name is {book}\")\n",
    "\n",
    "# books = ['The Midnight Library', 'The Alchemist', 'The Great Gatsby']\n",
    "\n",
    "\n",
    "# # for i in books:\n",
    "# #     result_pormt = prompt_template_name.format(book = i)\n",
    "# #     print(result_pormt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import LLMChain\n",
    "\n",
    "# review_chain = LLMChain(llm= model, prompt = prompt_template_name)\n",
    "\n",
    "\n",
    "# # result = review_chain.run(book = books)\n",
    "# # print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_summary = PromptTemplate(input_variables=['review'],\n",
    "#                                 template = \"i want review of the book in 2 points. the riview is {review}\")\n",
    "\n",
    "# prompt_summary_chain = LLMChain(llm = model, prompt = prompt_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "# chain = SimpleSequentialChain(chains = [review_chain,prompt_summary_chain])\n",
    "\n",
    "# for i in books:\n",
    "#     response = chain.run(book = i)\n",
    "#     print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_for_name = PromptTemplate(input_variables='names',\n",
    "                                template=\"can you suggest three name for my project, the context of the project is send bulk emails, and the name is {names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "promt_for_summary = PromptTemplate(input_variables=\"summary\",\n",
    "                                   template = \"i want summary of the project according to the name  and the summary is {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_Chain = LLMChain(llm = model, prompt = promt_for_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = LLMChain(llm = model, prompt = promt_for_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SimpleSequentialChain(chains = [name_Chain, summary_chain])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary for each project name, keeping in mind the desired tone:\n",
      "\n",
      "**1. MassMail:**  A simple tool for sending mass emails.\n",
      "\n",
      "**2. BulkEmailPro:** A professional-grade solution for efficient bulk email management and distribution.\n",
      "\n",
      "**3. EmailDispatch:**  A streamlined and efficient system for dispatching bulk emails, ensuring organized and timely delivery.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Run the chain (passing a single input)\n",
    "context = \"sending bulk emails\"\n",
    "result = final_chain.run(context)\n",
    "\n",
    "# Step 6: Output the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
